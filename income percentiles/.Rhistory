colnames(spa_raw)
shiny::runApp()
shiny::runApp()
# ── 0. Libraries ───────────────────────────────────────────────────────
library(shiny)
library(shinydashboard)
library(tidyverse)   # dplyr, purrr, ggplot2, etc.
library(janitor)
library(readxl)
library(DT)
library(plotly)
# ── 1. Data import & tidy  --------------------------------------------
load_spa <- function(path = "data clean.xlsx") {
read_excel(path, .name_repair = "minimal") %>%
clean_names() %>%
rename(
init_id     = id,
start       = start_time,
end         = completion_time,
initiative  = name_of_the_initiative,
is_new      = is_it_a_new_initiative_or_does_it_represent_a_significant_scaling_up_of_an_existing_successful_effort,
leads       = lead_implementing_countries_entities,
endorsers   = endorsing_countries_entities_this_list_can_be_updated_at_any_time_via_email_to_ffd4_spa_un_org,
ffd_areas   = specify_all_ffd_action_areas_the_initiative_will_address,
sdgs        = specify_all_sustainable_development_goals_the_initiative_will_address,
geo_focus   = specify_the_initiatives_geographic_focus,
description = brief_description_of_the_initiative_including_how_it_will_contribute_to_advancing_ffd_outcomes_max_3000_characters,
actions     = list_specific_actions_formulated_in_a_way_that_they_can_be_monitored_quantified_and_easily_communicated_wherever_possible_and_with_clear_implementation_timelines_max_3000_characters
) %>%
mutate(
start    = as.POSIXct(start, tz = "UTC"),
end      = as.POSIXct(end,   tz = "UTC"),
duration = as.numeric(difftime(end, start, units = "mins")),
across(c(sdgs, ffd_areas, geo_focus, leads, endorsers),
~ str_split(as.character(.x), ";|,|\\n") %>%
map(~ str_trim(.x) %>% discard(~ .x == "")))
)
}
spa_raw <- load_spa()
# helper: unique values from list-column --------------------------------
unique_from_listcol <- function(df, col) {
df %>% select({{col}}) %>% unnest({{col}}) %>%
distinct({{col}}) %>% arrange({{col}}) %>% pull()
}
ddl_sdgs <- unique_from_listcol(spa_raw, sdgs)
ddl_ffd  <- unique_from_listcol(spa_raw, ffd_areas)
ddl_geo  <- unique_from_listcol(spa_raw, geo_focus)
# helper: count values in a list-column ---------------------------------
count_multiselect <- function(df, col) {
df %>% select({{col}}) %>% unnest({{col}}) %>%
filter({{col}} != "" & !is.na({{col}})) %>%
count({{col}}, sort = TRUE, name = "count")
}
# helper: consistent bar plot ------------------------------------------
plot_bar <- function(df, label_col, n_show = 15, fill = "#03497a") {
ggplot(df %>% slice_head(n = n_show),
aes(reorder(.data[[label_col]], count), count)) +
geom_col(fill = fill) + coord_flip() +
labs(x = NULL, y = "Count") +
theme_minimal() +
theme(axis.text.y = element_text(size = 10))
}
# ── 2. UI --------------------------------------------------------------
ui <- dashboardPage(
dashboardHeader(title = "SPA Explorer"),
dashboardSidebar(
sidebarMenu(
menuItem("Summaries",   tabName = "summaries",   icon = icon("chart-bar")),
menuItem("Initiatives", tabName = "initiatives", icon = icon("table"))
),
hr(),
selectizeInput("filter_sdgs", "SDGs",
choices = c("All" = "", ddl_sdgs), multiple = TRUE),
selectizeInput("filter_ffd",  "FFD Areas",
choices = c("All" = "", ddl_ffd), multiple = TRUE),
selectizeInput("filter_geo",  "Geo Focus",
choices = c("All" = "", ddl_geo), multiple = TRUE)
),
dashboardBody(
tabItems(
tabItem("summaries",
fluidRow(valueBoxOutput("vb_count", width = 12)),
fluidRow(
box(title = "SDGs",           plotlyOutput("plot_sdgs"), width = 6),
box(title = "FFD Areas",      plotlyOutput("plot_ffd"),  width = 6)
),
fluidRow(
box(title = "New vs Scaling", plotlyOutput("plot_new"),  width = 6),
box(title = "Geographic Focus", plotlyOutput("plot_geo"), width = 6)
)
),
tabItem("initiatives",
box(DTOutput("tbl_init"), width = 12)
)
)
)
)
shiny::runApp()
shiny::runApp()
# ── 1. Data import & tidy ---------------------------------------------
load_spa <- function(path = "data clean.xlsx") {
read_excel(path, .name_repair = "minimal") %>%
clean_names() %>%
rename(
init_id     = id,
start       = start_time,
end         = completion_time,
initiative  = name_of_the_initiative,
is_new      = is_it_a_new_initiative_or_does_it_represent_a_significant_scaling_up_of_an_existing_successful_effort,
leads       = lead_implementing_countries_entities,
endorsers   = matches("^endorsing_countries"),
ffd_areas   = specify_all_ffd_action_areas_the_initiative_will_address,
sdgs        = specify_all_sustainable_development_goals_the_initiative_will_address,
geo_focus   = specify_the_initiatives_geographic_focus,
description = brief_description_of_the_initiative_including_how_it_will_contribute_to_advancing_ffd_outcomes_max_3000_characters,
actions     = matches("^list_specific_actions_")
) %>%
select(-email, -name, -last_modified_time) %>%
mutate(
start    = as.POSIXct(start, tz = "UTC"),
end      = as.POSIXct(end,   tz = "UTC"),
duration = as.numeric(difftime(end, start, units = "mins")),
across(c(sdgs, ffd_areas, geo_focus, leads, endorsers),
~ str_split(coalesce(as.character(.x), ""), ";|,|/|·|\\n") %>%
map(~ str_trim(.x) %>% discard(~ .x == "")))
) %>%
# Strip leading numbers from SDG labels ("1. No Poverty" -> "No Poverty")
mutate(sdgs = map(sdgs, ~ str_remove(.x, "^\\d+\\.\\s*")))
}
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
shiny::runApp()
runApp()
library(rsconnect)
# (run this only once per machine; you already did)
# rsconnect::setAccountInfo(name   = "tomershiny",
#                           token  = "06AE1AF6D26F0F7F683E4BF7508F7A3D",
#                           secret = "<SECRET>")
# Deploy
rsconnect::deployApp(
appName  = "spa-explorer",          # becomes the URL slug
appTitle = "Seville Platform for Action Explorer"
)
file.edit("~/.Rprofile")
shiny::runApp()
shiny::runApp()
# ── 0. Libraries ───────────────────────────────────────────────────────────
library(shiny)
library(shinydashboard)
library(tidyverse) # dplyr, purrr, ggplot2, stringr …
library(janitor)
library(readxl)
library(DT)
library(plotly)
# ── 1. Data import + tidy --------------------------------------------------
load_spa <- function(path = "data_clean.xlsx") {
read_excel(path, .name_repair = "minimal") %>%
clean_names() %>%
rename(
init_id     = id,
start       = start_time,
end         = completion_time,
initiative  = name_of_the_initiative,
is_new      = is_it_a_new_initiative_or_does_it_represent_a_significant_scaling_up_of_an_existing_successful_effort,
leads       = lead_implementing_countries_entities,
endorsers   = matches("^endorsing_countries"),
ffd_areas   = specify_all_ffd_action_areas_the_initiative_will_address,
sdgs        = specify_all_sustainable_development_goals_the_initiative_will_address,
geo_focus   = specify_the_initiatives_geographic_focus,
description = brief_description_of_the_initiative_including_how_it_will_contribute_to_advancing_ffd_outcomes_max_3000_characters,
actions     = matches("^list_specific_actions_")
) %>%
select(-email, -name, -last_modified_time) %>%
mutate(
start = as.POSIXct(start, tz = "UTC"),
end = as.POSIXct(end, tz = "UTC"),
duration = as.numeric(difftime(end, start, units = "mins")),
across(
c(sdgs, ffd_areas, geo_focus, leads, endorsers),
~ str_split(coalesce(as.character(.x), ""), ";|,|/|·|\\n") %>%
map(~ str_trim(.x) %>% discard(~ .x == ""))
)
) %>%
mutate(
sdgs = map(sdgs, ~ str_remove(.x, "^\\d+\\.\\s*")), # strip leading numbers
ffd_areas = map(ffd_areas, ~ {
.x %>%
str_replace_all(
"(?i)science|technology|innovation and capacity building",
"Science, Technology and Innovation"
) %>%
str_replace_all(
"(?i)data|monitoring and follow up",
"Data, Monitoring and Follow-up"
)
})
)
}
spa_raw <- load_spa()
glimpse(spa_raw)
# ── helpers ----------------------------------------------------------------
unique_from_listcol <- function(df, col) {
df %>%
select({{ col }}) %>%
unnest({{ col }}) %>%
distinct({{ col }}) %>%
arrange({{ col }}) %>%
pull()
}
count_multiselect <- function(df, col) {
df %>%
select({{ col }}) %>%
unnest({{ col }}) %>%
filter({{ col }} != "" & !is.na({{ col }})) %>%
count({{ col }}, sort = TRUE, name = "count")
}
colnames(spa_raw)
table(spa_raw$ffd_areas)
str(spa_raw$ffd_areas)
table(unlist(spa_raw$ffd_areas))
table(unlist(spa_raw$sdgs))
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
rsconnect::deployApp(
appName  = "spa-explorer",          # becomes the URL slug
appTitle = "Seville Platform for Action Explorer"
)
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
runApp()
library(rsconnect)
# (run this only once per machine; you already did)
# rsconnect::setAccountInfo(name   = "tomershiny",
#                           token  = "06AE1AF6D26F0F7F683E4BF7508F7A3D",
#                           secret = "<SECRET>")
# Deploy
rsconnect::deployApp(
appName  = "spa-explorer",          # becomes the URL slug
appTitle = "Seville Platform for Action Explorer"
)
shiny::runApp()
runApp()
shiny::runApp()
shiny::runApp()
library(rsconnect)
# (run this only once per machine; you already did)
# rsconnect::setAccountInfo(name   = "tomershiny",
#                           token  = "06AE1AF6D26F0F7F683E4BF7508F7A3D",
#                           secret = "<SECRET>")
# Deploy
rsconnect::deployApp(
appName  = "spa-explorer",          # becomes the URL slug
appTitle = "Seville Platform for Action Explorer"
)
library(readxl); library(janitor)
clean  <- names(read_excel("data_clean.xlsx",    n_max = 0)  |> clean_names())
approved <- names(read_excel("data_approved.xlsx", n_max = 0) |> clean_names())
setdiff(clean, approved)     # columns expected but NOT present in data_approved
setdiff(approved, clean)     # extra columns that are new (fine)
approved_data <- read_excel("data_approved.xlsx")
glimpse(approved_data)
library(readxl); library(janitor)
clean  <- names(read_excel("data_clean.xlsx",    n_max = 0)  |> clean_names())
approved <- names(read_excel("data_approved.xlsx", n_max = 0) |> clean_names())
approved_data <- read_excel("data_approved.xlsx")
setdiff(clean, approved)     # columns expected but NOT present in data_approved
setdiff(approved, clean)     # extra columns that are new (fine)
glimpse(approved_data)
library(readxl); library(janitor)
clean  <- names(read_excel("data_clean.xlsx",    n_max = 0)  |> clean_names())
approved <- names(read_excel("data_approved.xlsx", n_max = 0) |> clean_names())
approved_data <- read_excel("data_approved.xlsx")
setdiff(clean, approved)     # columns expected but NOT present in data_approved
setdiff(approved, clean)     # extra columns that are new (fine)
glimpse(approved_data)
runApp()
runApp()
shiny::runApp()
library(rsconnect)
# (run this only once per machine; you already did)
# rsconnect::setAccountInfo(name   = "tomershiny",
#                           token  = "06AE1AF6D26F0F7F683E4BF7508F7A3D",
#                           secret = "<SECRET>")
# Deploy
rsconnect::deployApp(
appName  = "spa-explorer",          # becomes the URL slug
appTitle = "Seville Platform for Action Explorer"
)
shiny::runApp()
shiny::runApp()
shiny::runApp()
runApp()
shiny::runApp()
shiny::runApp()
library(rsconnect)
# (run this only once per machine; you already did)
# rsconnect::setAccountInfo(name   = "tomershiny",
#                           token  = "06AE1AF6D26F0F7F683E4BF7508F7A3D",
#                           secret = "<SECRET>")
# Deploy
rsconnect::deployApp(
appName  = "spa-explorer",          # becomes the URL slug
appTitle = "Seville Platform for Action Explorer"
)
library(tidyverse)
library(scales)
library(ipumsr)
### read in acs.dat and acs.xml
# Load ACS microdata
acs <- read_ipums_micro(
ddi = "acs.xml",
data_file = "acs.dat"
) %>%
rename_with(tolower) %>%
select(perwt, year, age, marst) %>%
mutate(marst = as_factor(marst))
setwd("~/Documents/GitHub/acs_projects_personal/marriage rates")
library(tidyverse)
library(scales)
# Set working directory
setwd("~/Documents/GitHub/acs_projects_personal")
## read in acs.dat and acs.xml
# Load ACS microdata
acs <- read_ipums_micro(
ddi       = "acs data/acs.xml",
data_file = "acs data/acs.dat"
) %>%
rename_with(tolower) %>%
select(perwt, year, age, marst) %>%
mutate(marst = as_factor(marst))
library(tidyverse)
library(scales)
library(ipumsr)
# Set working directory
setwd("~/Documents/GitHub/acs_projects_personal")
## read in acs.dat and acs.xml
# Load ACS microdata
acs <- read_ipums_micro(
ddi       = "acs data/acs.xml",
data_file = "acs data/acs.dat"
) %>%
rename_with(tolower) %>%
select(perwt, year, age, marst) %>%
mutate(marst = as_factor(marst))
glimpse(acs)
library(tidyverse)
library(haven)
library(forcats)
library(scales)
# Set working directory to this project's folder
setwd("~/Documents/GitHub/acs_projects_personal/income percentiles")
# Load data
acs <- read_dta("acs.dta")
acs <- acs %>%
mutate(
incwage = as.numeric(incwage),
incwage = ifelse(incwage %in% c(999999, 999998), NA, incwage)
)
glimpse(acs)
# Specify the variables to convert
vars <- c(
"sex", "race", "hispan", "educ", "educd", "degfield", "marst",
"citizen", "empstat", "labforce"
)
acs <- acs %>%
mutate(across(all_of(vars), as_factor))
acs_employed <- acs %>%
filter(age >= 18 & age <= 65) %>%
filter(empstat == "employed") %>%
filter(!is.na(incwage)) %>%
filter(incwage > 0)
acs_employed_full_time <- acs %>%
filter(age >= 18 & age <= 65) %>%
filter(empstat == "employed") %>%
filter(uhrswork >= 35) %>%
filter(!is.na(incwage)) %>%
filter(incwage > 0)
acs_employed_full_time_college <- acs %>%
filter(age >= 18 & age <= 65) %>%
filter(empstat == "employed") %>%
filter(uhrswork >= 35) %>%
filter(educ == "4 years of college" | educ == "5+ years of college") %>%
filter(!is.na(incwage)) %>%
filter(incwage > 0)
# Create a function for percentile plots
create_percentile_plot <- function(data, title) {
data %>%
summarise(
p25 = quantile(incwage, 0.25, na.rm = TRUE),
median = median(incwage, na.rm = TRUE),
mean = mean(incwage, na.rm = TRUE),
p75 = quantile(incwage, 0.75, na.rm = TRUE),
p90 = quantile(incwage, 0.90, na.rm = TRUE),
p95 = quantile(incwage, 0.95, na.rm = TRUE),
p99 = quantile(incwage, 0.99, na.rm = TRUE)
) %>%
pivot_longer(everything(), names_to = "stat", values_to = "value") %>%
ggplot(aes(x = fct_reorder(stat, value), y = value, fill = stat)) +
geom_col(show.legend = FALSE) +
geom_text(aes(label = scales::dollar(value)), vjust = -0.5, size = 3) +
scale_fill_viridis_d(option = "D") +
scale_y_continuous(labels = scales::comma) +
labs(title = title, x = NULL, y = "Income ($)") +
theme_minimal(base_size = 14) +
theme(
axis.text.x = element_text(angle = 45, hjust = 1),
plot.title = element_text(face = "bold"),
panel.grid.minor = element_blank()
)
}
# Create plots using the function
overall_percentiles <- create_percentile_plot(acs, "Wage Income Distribution for All Americans")
print(overall_percentiles)
ggsave("overall_percentiles.png", width = 8, height = 6, units = "in")
employed_percentiles <- create_percentile_plot(acs_employed, "Wage Income Distribution for Employed Americans")
print(employed_percentiles)
ggsave("employed_percentiles.png", width = 8, height = 6, units = "in")
employed_full_time_percentiles <- create_percentile_plot(
acs_employed_full_time,
"Wage Income Distribution for Full-Time Employed Americans"
)
print(employed_full_time_percentiles)
ggsave("employed_full_time_percentiles.png", width = 8, height = 6, units = "in")
employed_full_time_college_percentiles <- create_percentile_plot(
acs_employed_full_time_college,
"Wage Income Distribution for Full-Time Employed College Graduates"
)
print(employed_full_time_college_percentiles)
ggsave("employed_full_time_college_percentiles.png", width = 8, height = 6, units = "in")
percentile_100k <- tibble(
dataset = c("Overall", "Employed", "Full-Time Employed", "Full-Time Employed College Grads"),
percentile = c(
ecdf(acs$incwage)(100000),
ecdf(acs_employed$incwage)(100000),
ecdf(acs_employed_full_time$incwage)(100000),
ecdf(acs_employed_full_time_college$incwage)(100000)
)
)
# Percentile of $100k bar chart – use single viridis colour
percentile_100k %>%
ggplot(aes(x = fct_reorder(dataset, desc(percentile)), y = percentile, fill = dataset)) +
geom_col(show.legend = FALSE) +
geom_text(aes(label = scales::percent(percentile, accuracy = 0.1)), vjust = -0.5, size = 3) +
scale_fill_viridis_d(option = "D") +
scale_y_continuous(labels = scales::percent) +
labs(title = "Percentile Rank of $100,000 Income", x = NULL, y = "Percentile") +
theme_minimal(base_size = 14) +
theme(
axis.text.x = element_text(angle = 20, hjust = 1),
plot.title = element_text(face = "bold")
)
ggsave("percentile_100k.png", width = 8, height = 6, units = "in")
# Create a function to show percentile of specific income
create_income_percentile_plot <- function(data, income_value, title) {
# Calculate the percentile
percentile <- ecdf(data$incwage)(income_value)
# Create the plot
data %>%
ggplot(aes(x = incwage)) +
geom_density(fill = "steelblue", alpha = 0.3) +
geom_vline(xintercept = income_value, color = "red", linetype = "dashed") +
annotate("text",
x = income_value,
y = max(density(data$incwage)$y),
label = paste0(
"$", scales::comma(income_value), "\n",
scales::percent(percentile, accuracy = 0.1), " percentile"
),
hjust = -0.1,
vjust = 1,
color = "red",
size = 4
) +
scale_x_continuous(labels = scales::dollar) +
labs(
title = title,
x = "Income",
y = "Density"
) +
theme_minimal() +
theme(
plot.title = element_text(size = 14, face = "bold"),
panel.grid.major = element_line(color = "gray90"),
panel.grid.minor = element_line(color = "gray95")
)
}
# Create the plot for full-time employed workers where you can choose any income level
full_time_income_plot <- create_income_percentile_plot(
acs_employed_full_time,
160000,
"Income Distribution for Full-Time Employed Workers\nwith $160,000 Income Level"
)
print(full_time_income_plot)
ggsave("full_time_income_distribution.png", width = 10, height = 6, units = "in")
